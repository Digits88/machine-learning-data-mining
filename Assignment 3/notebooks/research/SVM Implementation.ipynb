{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code from [this gist](https://gist.github.com/mblondel/97cffbea574a5890f0d7) commented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.55862138431\n",
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]\n",
      " [ 5.4  3.9  1.7  0.4]\n",
      " [ 4.6  3.4  1.4  0.3]\n",
      " [ 5.   3.4  1.5  0.2]\n",
      " [ 4.4  2.9  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.4  3.7  1.5  0.2]\n",
      " [ 4.8  3.4  1.6  0.2]\n",
      " [ 4.8  3.   1.4  0.1]\n",
      " [ 4.3  3.   1.1  0.1]\n",
      " [ 5.8  4.   1.2  0.2]\n",
      " [ 5.7  4.4  1.5  0.4]\n",
      " [ 5.4  3.9  1.3  0.4]\n",
      " [ 5.1  3.5  1.4  0.3]\n",
      " [ 5.7  3.8  1.7  0.3]\n",
      " [ 5.1  3.8  1.5  0.3]\n",
      " [ 5.4  3.4  1.7  0.2]\n",
      " [ 5.1  3.7  1.5  0.4]\n",
      " [ 4.6  3.6  1.   0.2]\n",
      " [ 5.1  3.3  1.7  0.5]\n",
      " [ 4.8  3.4  1.9  0.2]\n",
      " [ 5.   3.   1.6  0.2]\n",
      " [ 5.   3.4  1.6  0.4]\n",
      " [ 5.2  3.5  1.5  0.2]\n",
      " [ 5.2  3.4  1.4  0.2]\n",
      " [ 4.7  3.2  1.6  0.2]\n",
      " [ 4.8  3.1  1.6  0.2]\n",
      " [ 5.4  3.4  1.5  0.4]\n",
      " [ 5.2  4.1  1.5  0.1]\n",
      " [ 5.5  4.2  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.   3.2  1.2  0.2]\n",
      " [ 5.5  3.5  1.3  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 4.4  3.   1.3  0.2]\n",
      " [ 5.1  3.4  1.5  0.2]\n",
      " [ 5.   3.5  1.3  0.3]\n",
      " [ 4.5  2.3  1.3  0.3]\n",
      " [ 4.4  3.2  1.3  0.2]\n",
      " [ 5.   3.5  1.6  0.6]\n",
      " [ 5.1  3.8  1.9  0.4]\n",
      " [ 4.8  3.   1.4  0.3]\n",
      " [ 5.1  3.8  1.6  0.2]\n",
      " [ 4.6  3.2  1.4  0.2]\n",
      " [ 5.3  3.7  1.5  0.2]\n",
      " [ 5.   3.3  1.4  0.2]\n",
      " [ 7.   3.2  4.7  1.4]\n",
      " [ 6.4  3.2  4.5  1.5]\n",
      " [ 6.9  3.1  4.9  1.5]\n",
      " [ 5.5  2.3  4.   1.3]\n",
      " [ 6.5  2.8  4.6  1.5]\n",
      " [ 5.7  2.8  4.5  1.3]\n",
      " [ 6.3  3.3  4.7  1.6]\n",
      " [ 4.9  2.4  3.3  1. ]\n",
      " [ 6.6  2.9  4.6  1.3]\n",
      " [ 5.2  2.7  3.9  1.4]\n",
      " [ 5.   2.   3.5  1. ]\n",
      " [ 5.9  3.   4.2  1.5]\n",
      " [ 6.   2.2  4.   1. ]\n",
      " [ 6.1  2.9  4.7  1.4]\n",
      " [ 5.6  2.9  3.6  1.3]\n",
      " [ 6.7  3.1  4.4  1.4]\n",
      " [ 5.6  3.   4.5  1.5]\n",
      " [ 5.8  2.7  4.1  1. ]\n",
      " [ 6.2  2.2  4.5  1.5]\n",
      " [ 5.6  2.5  3.9  1.1]\n",
      " [ 5.9  3.2  4.8  1.8]\n",
      " [ 6.1  2.8  4.   1.3]\n",
      " [ 6.3  2.5  4.9  1.5]\n",
      " [ 6.1  2.8  4.7  1.2]\n",
      " [ 6.4  2.9  4.3  1.3]\n",
      " [ 6.6  3.   4.4  1.4]\n",
      " [ 6.8  2.8  4.8  1.4]\n",
      " [ 6.7  3.   5.   1.7]\n",
      " [ 6.   2.9  4.5  1.5]\n",
      " [ 5.7  2.6  3.5  1. ]\n",
      " [ 5.5  2.4  3.8  1.1]\n",
      " [ 5.5  2.4  3.7  1. ]\n",
      " [ 5.8  2.7  3.9  1.2]\n",
      " [ 6.   2.7  5.1  1.6]\n",
      " [ 5.4  3.   4.5  1.5]\n",
      " [ 6.   3.4  4.5  1.6]\n",
      " [ 6.7  3.1  4.7  1.5]\n",
      " [ 6.3  2.3  4.4  1.3]\n",
      " [ 5.6  3.   4.1  1.3]\n",
      " [ 5.5  2.5  4.   1.3]\n",
      " [ 5.5  2.6  4.4  1.2]\n",
      " [ 6.1  3.   4.6  1.4]\n",
      " [ 5.8  2.6  4.   1.2]\n",
      " [ 5.   2.3  3.3  1. ]\n",
      " [ 5.6  2.7  4.2  1.3]\n",
      " [ 5.7  3.   4.2  1.2]\n",
      " [ 5.7  2.9  4.2  1.3]\n",
      " [ 6.2  2.9  4.3  1.3]\n",
      " [ 5.1  2.5  3.   1.1]\n",
      " [ 5.7  2.8  4.1  1.3]\n",
      " [ 6.3  3.3  6.   2.5]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 7.1  3.   5.9  2.1]\n",
      " [ 6.3  2.9  5.6  1.8]\n",
      " [ 6.5  3.   5.8  2.2]\n",
      " [ 7.6  3.   6.6  2.1]\n",
      " [ 4.9  2.5  4.5  1.7]\n",
      " [ 7.3  2.9  6.3  1.8]\n",
      " [ 6.7  2.5  5.8  1.8]\n",
      " [ 7.2  3.6  6.1  2.5]\n",
      " [ 6.5  3.2  5.1  2. ]\n",
      " [ 6.4  2.7  5.3  1.9]\n",
      " [ 6.8  3.   5.5  2.1]\n",
      " [ 5.7  2.5  5.   2. ]\n",
      " [ 5.8  2.8  5.1  2.4]\n",
      " [ 6.4  3.2  5.3  2.3]\n",
      " [ 6.5  3.   5.5  1.8]\n",
      " [ 7.7  3.8  6.7  2.2]\n",
      " [ 7.7  2.6  6.9  2.3]\n",
      " [ 6.   2.2  5.   1.5]\n",
      " [ 6.9  3.2  5.7  2.3]\n",
      " [ 5.6  2.8  4.9  2. ]\n",
      " [ 7.7  2.8  6.7  2. ]\n",
      " [ 6.3  2.7  4.9  1.8]\n",
      " [ 6.7  3.3  5.7  2.1]\n",
      " [ 7.2  3.2  6.   1.8]\n",
      " [ 6.2  2.8  4.8  1.8]\n",
      " [ 6.1  3.   4.9  1.8]\n",
      " [ 6.4  2.8  5.6  2.1]\n",
      " [ 7.2  3.   5.8  1.6]\n",
      " [ 7.4  2.8  6.1  1.9]\n",
      " [ 7.9  3.8  6.4  2. ]\n",
      " [ 6.4  2.8  5.6  2.2]\n",
      " [ 6.3  2.8  5.1  1.5]\n",
      " [ 6.1  2.6  5.6  1.4]\n",
      " [ 7.7  3.   6.1  2.3]\n",
      " [ 6.3  3.4  5.6  2.4]\n",
      " [ 6.4  3.1  5.5  1.8]\n",
      " [ 6.   3.   4.8  1.8]\n",
      " [ 6.9  3.1  5.4  2.1]\n",
      " [ 6.7  3.1  5.6  2.4]\n",
      " [ 6.9  3.1  5.1  2.3]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 6.8  3.2  5.9  2.3]\n",
      " [ 6.7  3.3  5.7  2.5]\n",
      " [ 6.7  3.   5.2  2.3]\n",
      " [ 6.3  2.5  5.   1.9]\n",
      " [ 6.5  3.   5.2  2. ]\n",
      " [ 6.2  3.4  5.4  2.3]\n",
      " [ 5.9  3.   5.1  1.8]] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2] 114\n",
      "Partial gradient:  [ 1.  1.  1.]\n",
      "iter 1 violation 1.0 vsum 1.0\n",
      "0.333333333333\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Multiclass SVMs (Crammer-Singer formulation).\n",
    "\n",
    "A pure Python re-implementation of:\n",
    "\n",
    "Large-scale Multiclass Support Vector Machine Training via Euclidean Projection onto the Simplex.\n",
    "Mathieu Blondel, Akinori Fujino, and Naonori Ueda.\n",
    "ICPR 2014.\n",
    "http://www.mblondel.org/publications/mblondel-icpr2014.pdf\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "def projection_simplex(v, z=1):\n",
    "    \"\"\"\n",
    "    Projection onto the simplex:\n",
    "        w^* = argmin_w 0.5 ||w-v||^2 s.t. \\sum_i w_i = z, w_i >= 0\n",
    "    \"\"\"\n",
    "    # For other algorithms computing the same projection, see\n",
    "    # https://gist.github.com/mblondel/6f3b7aaad90606b98f71\n",
    "    n_features = v.shape[0]\n",
    "    u = np.sort(v)[::-1]\n",
    "    cssv = np.cumsum(u) - z # The cumulative sum of all the values in u\n",
    "    ind = np.arange(n_features) + 1\n",
    "    cond = u - cssv / ind > 0\n",
    "    rho = ind[cond][-1]\n",
    "    theta = cssv[cond][-1] / float(rho)\n",
    "    w = np.maximum(v - theta, 0)\n",
    "    return w\n",
    "\n",
    "\n",
    "class MulticlassSVM(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, C=1, max_iter=50, tol=0.05,\n",
    "                 random_state=None, verbose=0):\n",
    "        self.C = C\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol,\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def _partial_gradient(self, X, y, i):\n",
    "        # Partial gradient for the ith sample.\n",
    "        g = np.dot(X[i], self.coef_.T) + 1\n",
    "        print X, y, i\n",
    "        print \"Partial gradient: \", g\n",
    "        g[y[i]] -= 1\n",
    "        return g\n",
    "\n",
    "    def _violation(self, g, y, i):\n",
    "        # Optimality violation for the ith sample.\n",
    "        smallest = np.inf\n",
    "        for k in xrange(g.shape[0]):\n",
    "            if k == y[i] and self.dual_coef_[k, i] >= self.C:\n",
    "                continue\n",
    "            elif k != y[i] and self.dual_coef_[k, i] >= 0:\n",
    "                continue\n",
    "\n",
    "            smallest = min(smallest, g[k])\n",
    "\n",
    "        return g.max() - smallest\n",
    "\n",
    "    def _solve_subproblem(self, g, y, norms, i):\n",
    "        # Prepare inputs to the projection.\n",
    "        Ci = np.zeros(g.shape[0])\n",
    "        Ci[y[i]] = self.C\n",
    "        beta_hat = norms[i] * (Ci - self.dual_coef_[:, i]) + g / norms[i]\n",
    "        z = self.C * norms[i]\n",
    "\n",
    "        # Compute projection onto the simplex.\n",
    "        beta = projection_simplex(beta_hat, z)\n",
    "\n",
    "        return Ci - self.dual_coef_[:, i] - beta / norms[i]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Normalize labels.\n",
    "        self._label_encoder = LabelEncoder()\n",
    "        y = self._label_encoder.fit_transform(y)\n",
    "\n",
    "        # Initialize primal and dual coefficients.\n",
    "        n_classes = len(self._label_encoder.classes_)\n",
    "        self.dual_coef_ = np.zeros((n_classes, n_samples), dtype=np.float64)\n",
    "        self.coef_ = np.zeros((n_classes, n_features))\n",
    "\n",
    "        # Pre-compute norms of all the feature vectors\n",
    "        norms = np.sqrt(np.sum(X ** 2, axis=1))\n",
    "\n",
    "        # Shuffle sample indices.\n",
    "        rs = check_random_state(self.random_state)\n",
    "        ind = np.arange(n_samples)\n",
    "        rs.shuffle(ind)\n",
    "\n",
    "        violation_init = None\n",
    "        for it in xrange(self.max_iter):\n",
    "            violation_sum = 0\n",
    "\n",
    "            for ii in xrange(n_samples):\n",
    "                i = ind[ii] # Grab a random sample\n",
    "                \n",
    "                # All-zero samples can be safely ignored.\n",
    "                if norms[i] == 0: # if norm feature vector = 0\n",
    "                    continue # skip\n",
    "\n",
    "                print norms[i]\n",
    "                \n",
    "                g = self._partial_gradient(X, y, i)\n",
    "                v = self._violation(g, y, i)\n",
    "                violation_sum += v\n",
    "\n",
    "                if v < 1e-12:\n",
    "                    continue\n",
    "\n",
    "                # Solve subproblem for the ith sample.\n",
    "                delta = self._solve_subproblem(g, y, norms, i)\n",
    "\n",
    "                # Update primal and dual coefficients.\n",
    "                self.coef_ += (delta * X[i][:, np.newaxis]).T\n",
    "                self.dual_coef_[:, i] += delta\n",
    "                \n",
    "                break\n",
    "\n",
    "            if it == 0:\n",
    "                violation_init = violation_sum\n",
    "\n",
    "            vratio = violation_sum / violation_init\n",
    "\n",
    "            if self.verbose >= 1:\n",
    "                print \"iter\", it + 1, \"violation\", vratio, \"vsum\", violation_sum\n",
    "\n",
    "            if vratio < self.tol:\n",
    "                if self.verbose >= 1:\n",
    "                    print \"Converged\"\n",
    "                break\n",
    "                \n",
    "            break\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        decision = np.dot(X, self.coef_.T)\n",
    "        pred = decision.argmax(axis=1)\n",
    "        return self._label_encoder.inverse_transform(pred)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from sklearn.datasets import load_iris\n",
    "\n",
    "    iris = load_iris()\n",
    "    X, y = iris.data, iris.target\n",
    "    \n",
    "    clf = MulticlassSVM(C=0.1, tol=0.01, max_iter=100, random_state=0, verbose=1)\n",
    "    clf.fit(X, y)\n",
    "    print clf.score(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
